{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import merge, Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "source": [
    "Test pobranego modelu w całości "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "train_dir = \"kaggle_bee_vs_wasp/\"\n",
    "bs = 32 # Batch size\n",
    "resize_size = 224 # for training, resize all the images to a square of this size\n",
    "training_subsample = 1 # for development, use a small fraction of the entire dataset rater than full dataset\n",
    "\n",
    "bees_vs_wasps_dataset_path=Path(train_dir) # this is relative to the \"example_notebook\" folder. Modify this to reflect your setup\n",
    "df_labels = pd.read_csv(bees_vs_wasps_dataset_path/'labels.csv')\n",
    "df_labels=df_labels.set_index('id')\n",
    "# perform dataset subsampling\n",
    "df_labels = df_labels.sample(frac=training_subsample, axis=0)\n",
    "insect_class = {'bee': 0,'wasp': 1, 'insect': 2,'other': 3} \n",
    "#df_labels.label = [insect_class[item] for item in df_labels.label] \n",
    "df_labels = df_labels[['path','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to read data from csv\n",
    "#df_labels = pd.read_csv(\"Dataset_full.csv\") #full dataset\n",
    "#df_labels = pd.read_csv(\"Dataset_10precent.csv\") #0.1 fraction for development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_val_df = train_test_split(df_labels, test_size=0.2)\n",
    "test_df, validation_df = train_test_split(test_val_df, test_size=0.5)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_last_layer\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 1024)              25691136  \n_________________________________________________________________\nfc2 (Dense)                  (None, 1024)              1049600   \n_________________________________________________________________\noutput (Dense)               (None, 4)                 4100      \n=================================================================\nTotal params: 41,459,524\nTrainable params: 29,104,644\nNon-trainable params: 12,354,880\n_________________________________________________________________\nModel: \"model_last_2_layers\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 1024)              25691136  \n_________________________________________________________________\nfc2 (Dense)                  (None, 1024)              1049600   \n_________________________________________________________________\noutput (Dense)               (None, 4)                 4100      \n=================================================================\nTotal params: 41,459,524\nTrainable params: 31,464,452\nNon-trainable params: 9,995,072\n_________________________________________________________________\nModel: \"model_full\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 1024)              25691136  \n_________________________________________________________________\nfc2 (Dense)                  (None, 1024)              1049600   \n_________________________________________________________________\noutput (Dense)               (None, 4)                 4100      \n=================================================================\nTotal params: 41,459,524\nTrainable params: 41,459,524\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create custom vgg models\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Model with last convolutional layer to train\n",
    "\n",
    "model1 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "last_layer = model1.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "out = Dense(4, activation='softmax', name='output')(x)\n",
    "\n",
    "model_last_layer = Model(image_input, out, name=\"model_last_layer\")\n",
    "\n",
    "for layer in model_last_layer.layers[:-6]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# Model with 2 last convolutional layers to train\n",
    "\n",
    "model2 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "last_layer = model2.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "out = Dense(4, activation='softmax', name='output')(x)\n",
    "model_last_2_layers = Model(image_input, out, name=\"model_last_2_layers\")\n",
    "\n",
    "for layer in model_last_2_layers.layers[:-7]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# Full train model\n",
    "\n",
    "model3 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "last_layer = model3.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "out = Dense(4, activation='softmax', name='output')(x)\n",
    "\n",
    "model_full = Model(image_input, out, name=\"model_full\")\n",
    "\n",
    "\n",
    "\n",
    "model_last_layer.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "model_last_2_layers.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "model_full.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "\n",
    "model_last_layer.summary()\n",
    "model_last_2_layers.summary()\n",
    "model_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 9136 validated image filenames belonging to 4 classes.\n",
      "Found 1143 validated image filenames belonging to 4 classes.\n",
      "Found 1142 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Create generators from dataframes\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    train_dir,  \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=bs\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validation_df, \n",
    "    train_dir, \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=bs\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    train_dir, \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    \"model_last_layer_checkpoint.hdf5\", \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=False,\n",
    "    save_weights_only=False, \n",
    "    mode='auto', \n",
    "    save_freq='epoch',\n",
    "    options=None\n",
    ")\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    \"model_last_2_layers_checkpoint.hdf5\", \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=False,\n",
    "    save_weights_only=False, \n",
    "    mode='auto', \n",
    "    save_freq='epoch',\n",
    "    options=None\n",
    ")\n",
    "checkpoint3 = ModelCheckpoint(\n",
    "    \"model_full_checkpoint.hdf5\", \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=False,\n",
    "    save_weights_only=False, \n",
    "    mode='auto', \n",
    "    save_freq='epoch',\n",
    "    options=None\n",
    ")\n",
    "early = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=40,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 1.1013 - accuracy: 0.5422\n",
      "Epoch 00001: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1430s 5s/step - loss: 1.1013 - accuracy: 0.5422 - val_loss: 0.9532 - val_accuracy: 0.6366\n",
      "Epoch 2/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.8879 - accuracy: 0.6765\n",
      "Epoch 00002: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1378s 5s/step - loss: 0.8879 - accuracy: 0.6765 - val_loss: 0.7709 - val_accuracy: 0.7241\n",
      "Epoch 3/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.7586 - accuracy: 0.7256\n",
      "Epoch 00003: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1384s 5s/step - loss: 0.7586 - accuracy: 0.7256 - val_loss: 0.6745 - val_accuracy: 0.7545\n",
      "Epoch 4/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.6765 - accuracy: 0.7508\n",
      "Epoch 00004: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1374s 5s/step - loss: 0.6765 - accuracy: 0.7508 - val_loss: 0.5914 - val_accuracy: 0.7955\n",
      "Epoch 5/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.7750\n",
      "Epoch 00005: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1377s 5s/step - loss: 0.6157 - accuracy: 0.7750 - val_loss: 0.5602 - val_accuracy: 0.8000\n",
      "Epoch 6/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.7959\n",
      "Epoch 00006: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1373s 5s/step - loss: 0.5781 - accuracy: 0.7959 - val_loss: 0.5191 - val_accuracy: 0.8188\n",
      "Epoch 7/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.8053\n",
      "Epoch 00007: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1373s 5s/step - loss: 0.5429 - accuracy: 0.8053 - val_loss: 0.5058 - val_accuracy: 0.8170\n",
      "Epoch 8/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.8125\n",
      "Epoch 00008: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1374s 5s/step - loss: 0.5171 - accuracy: 0.8125 - val_loss: 0.4842 - val_accuracy: 0.8223\n",
      "Epoch 9/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.8211\n",
      "Epoch 00009: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1377s 5s/step - loss: 0.4971 - accuracy: 0.8211 - val_loss: 0.4624 - val_accuracy: 0.8366\n",
      "Epoch 10/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.8261\n",
      "Epoch 00010: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1383s 5s/step - loss: 0.4802 - accuracy: 0.8261 - val_loss: 0.4478 - val_accuracy: 0.8429\n",
      "Epoch 11/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.8349\n",
      "Epoch 00011: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1350s 5s/step - loss: 0.4623 - accuracy: 0.8349 - val_loss: 0.4449 - val_accuracy: 0.8402\n",
      "Epoch 12/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.8380\n",
      "Epoch 00012: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1364s 5s/step - loss: 0.4532 - accuracy: 0.8380 - val_loss: 0.4359 - val_accuracy: 0.8420\n",
      "Epoch 13/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8416\n",
      "Epoch 00013: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1354s 5s/step - loss: 0.4421 - accuracy: 0.8416 - val_loss: 0.4335 - val_accuracy: 0.8420\n",
      "Epoch 14/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.8415\n",
      "Epoch 00014: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1371s 5s/step - loss: 0.4347 - accuracy: 0.8415 - val_loss: 0.4064 - val_accuracy: 0.8554\n",
      "Epoch 15/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.8466\n",
      "Epoch 00015: saving model to model_last_layer_checkpoint.hdf5\n",
      "285/285 [==============================] - 1371s 5s/step - loss: 0.4225 - accuracy: 0.8466 - val_loss: 0.4040 - val_accuracy: 0.8545\n",
      "Epoch 1/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 1.0699 - accuracy: 0.5633\n",
      "Epoch 00001: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1495s 5s/step - loss: 1.0699 - accuracy: 0.5633 - val_loss: 0.8758 - val_accuracy: 0.6687\n",
      "Epoch 2/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.8124 - accuracy: 0.6971\n",
      "Epoch 00002: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1483s 5s/step - loss: 0.8124 - accuracy: 0.6971 - val_loss: 0.6850 - val_accuracy: 0.7420\n",
      "Epoch 3/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.7500\n",
      "Epoch 00003: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1482s 5s/step - loss: 0.6736 - accuracy: 0.7500 - val_loss: 0.5778 - val_accuracy: 0.7955\n",
      "Epoch 4/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.7853\n",
      "Epoch 00004: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1491s 5s/step - loss: 0.5896 - accuracy: 0.7853 - val_loss: 0.5199 - val_accuracy: 0.8107\n",
      "Epoch 5/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.8026\n",
      "Epoch 00005: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1541s 5s/step - loss: 0.5359 - accuracy: 0.8026 - val_loss: 0.4835 - val_accuracy: 0.8241\n",
      "Epoch 6/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.8192\n",
      "Epoch 00006: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1564s 5s/step - loss: 0.4968 - accuracy: 0.8192 - val_loss: 0.4572 - val_accuracy: 0.8304\n",
      "Epoch 7/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.8306\n",
      "Epoch 00007: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1573s 6s/step - loss: 0.4634 - accuracy: 0.8306 - val_loss: 0.4339 - val_accuracy: 0.8357\n",
      "Epoch 8/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.8409\n",
      "Epoch 00008: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1230s 4s/step - loss: 0.4452 - accuracy: 0.8409 - val_loss: 0.4364 - val_accuracy: 0.8393\n",
      "Epoch 9/15\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.8457\n",
      "Epoch 00009: saving model to model_last_2_layers_checkpoint.hdf5\n",
      "285/285 [==============================] - 1014s 4s/step - loss: 0.4298 - accuracy: 0.8457 - val_loss: 0.4099 - val_accuracy: 0.8482\n",
      "Epoch 10/15\n",
      "196/285 [===================>..........] - ETA: 4:52 - loss: 0.4168 - accuracy: 0.8505"
     ]
    }
   ],
   "source": [
    "n_training_samples = len(train_df)\n",
    "n_validation_samples = len(validation_df)\n",
    "\n",
    "history1 = model_last_layer.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs,\n",
    "    callbacks=[checkpoint1, early])\n",
    "\n",
    "history2 = model_last_2_layers.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs,\n",
    "    callbacks=[checkpoint2, early])\n",
    "\n",
    "history3 = model_full.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs,\n",
    "    callbacks=[checkpoint3, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1142/1142 [==============================] - 121s 106ms/step - loss: 0.3630 - accuracy: 0.2767\n",
      "[0.36303287744522095, 0.2767075300216675]\n"
     ]
    }
   ],
   "source": [
    "model_last_layer = load_model('model_last_layer_checkpoint.hdf5')\n",
    "filenames = test_generator.filenames\n",
    "n_test_samples = len(filenames)\n",
    "scores1 = model_last_layer.evaluate(test_generator,steps=n_test_samples)\n",
    "print (scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_last_layer = load_model('model_last_layer_checkpoint.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-cce405f8406c>:4: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use Model.evaluate, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "filenames = test_generator.filenames\n",
    "n_test_samples = len(filenames)\n",
    "#predict = custom_vgg_model.predict(test_generator, steps=n_test_samples)\n",
    "scores1 = model_last_layer.evaluate(test_generator,steps=n_test_samples)\n",
    "scores2 = model_last_2_layers.evaluate(test_generator,steps=n_test_samples)\n",
    "scores3 = model_full.evaluate(test_generator,steps=n_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model_last_layer' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-818cf4df05be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_last_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'last_layer_trained_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m np.savetxt(\"model1_class/val_loss.csv\",  \n\u001b[0;32m      3\u001b[0m            \u001b[0mhistory1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m            \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\", \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m            fmt ='% s') \n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_last_layer' is not defined"
     ]
    }
   ],
   "source": [
    "model_last_layer.save('last_layer_trained_model')\n",
    "np.savetxt(\"model3_last_layer/val_loss.csv\",  \n",
    "           history1.history[\"val_loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/val_accuracy.csv\",  \n",
    "           history1.history[\"val_accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/loss.csv\",  \n",
    "           history1.history[\"loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/accuracy.csv\",  \n",
    "           history1.history[\"accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/accuracy_on_test.csv\",  \n",
    "           scores1, \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "\n",
    "model_last_2_layers.save('last_2_layers_trained_model')\n",
    "np.savetxt(\"model4_last_2layers/val_loss.csv\",  \n",
    "           history2.history[\"val_loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/val_accuracy.csv\",  \n",
    "           history2.history[\"val_accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/loss.csv\",  \n",
    "           history2.history[\"loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/accuracy.csv\",  \n",
    "           history2.history[\"accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/accuracy_on_test.csv\",  \n",
    "           scores2, \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "\n",
    "model_full.save('full_trained_model')\n",
    "np.savetxt(\"model5_full/val_loss.csv\",  \n",
    "           history3.history[\"val_loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/val_accuracy.csv\",  \n",
    "           history3.history[\"val_accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/loss.csv\",  \n",
    "           history3.history[\"loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/accuracy.csv\",  \n",
    "           history3.history[\"accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/accuracy_on_test.csv\",  \n",
    "           scores3, \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1 accuracy on test set:0.27272728085517883\nModel 2 accuracy on test set:0.1818181872367859\nModel 3 accuracy on test set:None\n"
     ]
    }
   ],
   "source": [
    "print (\"Model 1 accuracy on test set:\" + str(scores1[1]) )\n",
    "print (\"Model 2 accuracy on test set:\" + str(scores2[1]) )\n",
    "print (\"Model 3 accuracy on test set:\" + str(scores3[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}