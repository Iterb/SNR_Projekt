{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model"
   ]
  },
  {
   "source": [
    "Test pobranego modelu w całości - przy wykorzystywaniu ImageNet mamy 1000 klas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import model\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions (Dense)          (None, 1000)              4097000   \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "# load an image from file\n",
    "image = load_img('wasp.jpg', target_size=(224, 224))\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bee (32.78%)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "source": [
    "Zadanie 1a"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "train_dir = \"kaggle_bee_vs_wasp/\"\n",
    "bs = 64 # Batch size\n",
    "resize_size = 96 # for training, resize all the images to a square of this size\n",
    "training_subsample = 0.1 # for development, use a small fraction of the entire dataset rater than full dataset\n",
    "\n",
    "\n",
    "\n",
    "bees_vs_wasps_dataset_path=Path(train_dir) # this is relative to the \"example_notebook\" folder. Modify this to reflect your setup\n",
    "df_labels = pd.read_csv(bees_vs_wasps_dataset_path/'labels.csv')\n",
    "df_labels=df_labels.set_index('id')\n",
    "# perform dataset subsampling\n",
    "df_labels = df_labels.sample(frac=training_subsample, axis=0)\n",
    "insect_class = {'bee': 0,'wasp': 1, 'insect': 2,'other': 3} \n",
    "#df_labels.label = [insect_class[item] for item in df_labels.label] \n",
    "df_labels = df_labels[['path','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(df_labels, test_size=0.1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 96, 96, 3)]       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 96, 96, 64)        1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 96, 96, 64)        36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 48, 48, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 48, 48, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 48, 48, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 24, 24, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 24, 24, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 24, 24, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 24, 24, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = VGG16(include_top=False, weights= \"imagenet\",input_shape=(resize_size, resize_size, 3))\n",
    "print(pretrained_model.summary())\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = pretrained_model.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "     \n",
    "x = Flatten()(last_output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(pretrained_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 96, 96, 3)]       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 96, 96, 64)        1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 96, 96, 64)        36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 48, 48, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 48, 48, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 48, 48, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 24, 24, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 24, 24, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 24, 24, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 24, 24, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 4608)              0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 1024)              4719616   \n_________________________________________________________________\ndense_13 (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\ndense_14 (Dense)             (None, 4)                 4100      \n=================================================================\nTotal params: 20,488,004\nTrainable params: 5,773,316\nNon-trainable params: 14,714,688\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1027 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    train_dir,  \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=bs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 115 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validation_df, \n",
    "    train_dir, \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=bs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "16/16 [==============================] - 13s 824ms/step - loss: 1.2646 - accuracy: 0.4465 - val_loss: 1.3193 - val_accuracy: 0.3594\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 13s 843ms/step - loss: 1.1986 - accuracy: 0.4642 - val_loss: 1.2812 - val_accuracy: 0.3906\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 13s 802ms/step - loss: 1.1634 - accuracy: 0.5202 - val_loss: 1.2728 - val_accuracy: 0.4219\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 13s 819ms/step - loss: 1.1267 - accuracy: 0.5369 - val_loss: 1.2214 - val_accuracy: 0.3906\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 14s 884ms/step - loss: 1.1206 - accuracy: 0.4984 - val_loss: 1.1728 - val_accuracy: 0.4375\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 14s 851ms/step - loss: 1.0954 - accuracy: 0.5576 - val_loss: 1.1311 - val_accuracy: 0.4531\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 13s 840ms/step - loss: 1.0676 - accuracy: 0.5670 - val_loss: 1.1800 - val_accuracy: 0.4844\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 14s 880ms/step - loss: 1.0617 - accuracy: 0.5639 - val_loss: 1.2366 - val_accuracy: 0.4688\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 14s 846ms/step - loss: 1.0397 - accuracy: 0.5794 - val_loss: 1.2161 - val_accuracy: 0.4375\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 13s 842ms/step - loss: 1.0320 - accuracy: 0.5659 - val_loss: 1.0819 - val_accuracy: 0.5469\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 14s 875ms/step - loss: 1.0139 - accuracy: 0.6221 - val_loss: 1.0010 - val_accuracy: 0.6562\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 14s 845ms/step - loss: 0.9973 - accuracy: 0.6012 - val_loss: 1.0844 - val_accuracy: 0.5312\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 13s 833ms/step - loss: 0.9772 - accuracy: 0.6355 - val_loss: 1.0722 - val_accuracy: 0.5781\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 14s 869ms/step - loss: 0.9735 - accuracy: 0.6251 - val_loss: 0.9744 - val_accuracy: 0.6250\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 14s 858ms/step - loss: 0.9632 - accuracy: 0.6376 - val_loss: 1.0432 - val_accuracy: 0.5938\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 14s 878ms/step - loss: 0.9552 - accuracy: 0.6521 - val_loss: 1.0349 - val_accuracy: 0.5781\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 14s 859ms/step - loss: 0.9465 - accuracy: 0.6501 - val_loss: 0.9997 - val_accuracy: 0.5938\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 14s 874ms/step - loss: 0.9321 - accuracy: 0.6511 - val_loss: 1.1782 - val_accuracy: 0.5156\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 14s 856ms/step - loss: 0.9304 - accuracy: 0.6490 - val_loss: 1.0054 - val_accuracy: 0.5938\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 13s 843ms/step - loss: 0.9172 - accuracy: 0.6480 - val_loss: 1.1348 - val_accuracy: 0.5625\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 14s 862ms/step - loss: 0.9162 - accuracy: 0.6667 - val_loss: 1.0753 - val_accuracy: 0.5312\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 14s 853ms/step - loss: 0.8992 - accuracy: 0.6687 - val_loss: 0.9744 - val_accuracy: 0.6250\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 14s 881ms/step - loss: 0.9013 - accuracy: 0.6625 - val_loss: 1.0441 - val_accuracy: 0.5781\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 14s 862ms/step - loss: 0.8825 - accuracy: 0.6729 - val_loss: 1.0579 - val_accuracy: 0.6406\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 14s 856ms/step - loss: 0.8723 - accuracy: 0.6687 - val_loss: 1.0806 - val_accuracy: 0.6094\n"
     ]
    }
   ],
   "source": [
    "n_training_samples = len(train_df)\n",
    "n_validation_samples = len(validation_df)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.3192517757415771,\n",
       " 1.2812132835388184,\n",
       " 1.272782325744629,\n",
       " 1.2214078903198242,\n",
       " 1.1727538108825684,\n",
       " 1.1311153173446655,\n",
       " 1.1799753904342651,\n",
       " 1.23663330078125,\n",
       " 1.2160691022872925,\n",
       " 1.0819427967071533,\n",
       " 1.0010037422180176,\n",
       " 1.0843676328659058,\n",
       " 1.0721657276153564,\n",
       " 0.9744089841842651,\n",
       " 1.0431559085845947,\n",
       " 1.0349478721618652,\n",
       " 0.999741792678833,\n",
       " 1.1782153844833374,\n",
       " 1.0053977966308594,\n",
       " 1.134765386581421,\n",
       " 1.0752544403076172,\n",
       " 0.9743689894676208,\n",
       " 1.0440798997879028,\n",
       " 1.0578973293304443,\n",
       " 1.080617904663086]"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "history.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}